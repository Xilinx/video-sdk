<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>GStreamer Introductory Tutorials &mdash; Xilinx Video SDK 2.0.1 (Production) documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="GStreamer Examples using Software Filters" href="filters.html" />
    <link rel="prev" title="Video Quality Examples" href="../ffmpeg/quality_analysis.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../index.html" class="icon icon-home"> Xilinx Video SDK
            <img src="../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started_on_prem.html">On Premises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started_on_vt1.html">Amazon EC2 VT1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../container_setup.html">Container Setup</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../examples.html">Tutorials and Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../ffmpeg/tutorials.html">FFmpeg Introductory Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ffmpeg/filters.html">FFmpeg Software Filters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ffmpeg/quality_analysis.html">FFmpeg Video Quality</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">GStreamer Introductory Tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-setup">Environment Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simple-gstreamer-examples">Simple GStreamer Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decode-only">Decode only</a></li>
<li class="toctree-l4"><a class="reference internal" href="#encode-only">Encode only</a></li>
<li class="toctree-l4"><a class="reference internal" href="#basic-transcode">Basic Transcode</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decode-only-into-multiple-resolution-outputs">Decode only into Multiple-Resolution outputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#encode-only-into-multiple-resolution-outputs">Encode only into Multiple-Resolution outputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transcode-with-multiple-resolution-outputs">Transcode with Multiple-Resolution outputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lower-latency-transcode-with-multiple-resolution-outputs">Lower-Latency Transcode With Multiple-Resolution outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#encoding-streams-to-4k">Encoding Streams to 4K</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#k-h-264-real-time-encode-only">4K H.264 Real-Time Encode Only</a></li>
<li class="toctree-l4"><a class="reference internal" href="#k-h-264-real-time-transcode">4K H.264 Real-Time Transcode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#running-on-multiple-devices">Running on Multiple Devices</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#running-multiple-jobs-using-the-vvas-xabrladder-application">Running Multiple Jobs using the vvas_xabrladder Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transcode-with-lookahead-for-multiple-resolution-outputs">Transcode with lookahead for Multiple-Resolution outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#faster-than-real-time">Faster than Real-Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="#streaming-examples">Streaming Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#replay-saved-files-with-downscaling">Replay Saved Files with Downscaling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="filters.html">GStreamer Software Filters</a></li>
<li class="toctree-l2"><a class="reference internal" href="quality_analysis.html">GStreamer Video Quality</a></li>
<li class="toctree-l2"><a class="reference internal" href="xcompositor.html">GStreamer Compositor</a></li>
<li class="toctree-l2"><a class="reference internal" href="xabrladder.html">GStreamer ABR Ladder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../xma/xma_apps.html">C-Based Applications</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../specs_and_features.html">Specs and Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../using_ffmpeg.html">Using FFmpeg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../using_gstreamer.html">Using GStreamer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tuning_encoding_quality.html">Tuning Quality of Encoded Video</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../managing_compute_resources.html">Managing Compute Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploying_with_kubernetes.html">Deploying with Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../c_apis.html">C API Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../card_management.html">Card Management</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/video-sdk/issues">File an issue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/video-sdk/browse.html">Other versions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Xilinx Video SDK</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../examples.html">Tutorials and Examples</a> &raquo;</li>
      <li>GStreamer Introductory Tutorials</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="gstreamer-introductory-tutorials">
<span id="gstreamer-tutorials"></span><h1>GStreamer Introductory Tutorials<a class="headerlink" href="#gstreamer-introductory-tutorials" title="Permalink to this heading">¶</a></h1>
<p>This page provides tutorials on how to use GStreamer with the Xilinx Video SDK. Detailed documentation for this specific topic can be found in the Xilinx Video SDK <a class="reference internal" href="../../using_gstreamer.html"><span class="doc">User Guide</span></a>.</p>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#environment-setup" id="id1">Environment Setup</a></p></li>
<li><p><a class="reference internal" href="#simple-gstreamer-examples" id="id2">Simple GStreamer Examples</a></p>
<ul>
<li><p><a class="reference internal" href="#decode-only" id="id3">Decode only</a></p></li>
<li><p><a class="reference internal" href="#encode-only" id="id4">Encode only</a></p></li>
<li><p><a class="reference internal" href="#basic-transcode" id="id5">Basic Transcode</a></p></li>
<li><p><a class="reference internal" href="#decode-only-into-multiple-resolution-outputs" id="id6">Decode only into Multiple-Resolution outputs</a></p></li>
<li><p><a class="reference internal" href="#encode-only-into-multiple-resolution-outputs" id="id7">Encode only into Multiple-Resolution outputs</a></p></li>
<li><p><a class="reference internal" href="#transcode-with-multiple-resolution-outputs" id="id8">Transcode with Multiple-Resolution outputs</a></p></li>
<li><p><a class="reference internal" href="#lower-latency-transcode-with-multiple-resolution-outputs" id="id9">Lower-Latency Transcode With Multiple-Resolution outputs</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#encoding-streams-to-4k" id="id10">Encoding Streams to 4K</a></p>
<ul>
<li><p><a class="reference internal" href="#k-h-264-real-time-encode-only" id="id11">4K H.264 Real-Time Encode Only</a></p></li>
<li><p><a class="reference internal" href="#k-h-264-real-time-transcode" id="id12">4K H.264 Real-Time Transcode</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#running-on-multiple-devices" id="id13">Running on Multiple Devices</a></p>
<ul>
<li><p><a class="reference internal" href="#running-multiple-jobs-using-the-vvas-xabrladder-application" id="id14">Running Multiple Jobs using the vvas_xabrladder Application</a></p></li>
<li><p><a class="reference internal" href="#transcode-with-lookahead-for-multiple-resolution-outputs" id="id15">Transcode with lookahead for Multiple-Resolution outputs</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#faster-than-real-time" id="id16">Faster than Real-Time</a></p></li>
<li><p><a class="reference internal" href="#streaming-examples" id="id17">Streaming Examples</a></p>
<ul>
<li><p><a class="reference internal" href="#replay-saved-files-with-downscaling" id="id18">Replay Saved Files with Downscaling</a></p></li>
</ul>
</li>
</ul>
</div>
<section id="environment-setup">
<h2><a class="toc-backref" href="#id1">Environment Setup</a><a class="headerlink" href="#environment-setup" title="Permalink to this heading">¶</a></h2>
<p>Set up the runtime environment:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>source /opt/xilinx/xcdr/setup.sh
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/xcdr/setup.sh</span></code> script exports important environment variables, starts the Xilinx Resource Manager (XRM) daemon, and ensures that the Xilinx devices and the XRM plugins are properly loaded. It also sets up the plugins needed for GStreamer solution of the Xilinx Video SDK and makes the pre-built GStreamer abrscaler and compositor applications available in the $PATH.</p>
<p>Sourcing of the setup scripts should be performed each time you open a new terminal on your system. This is required for the environment to be correctly configured.  If the runtime environment is not correctly set up, running the examples below will result in errors like “xbutil: command not found” or “plugins not loaded” errors</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
<section id="simple-gstreamer-examples">
<h2><a class="toc-backref" href="#id2">Simple GStreamer Examples</a><a class="headerlink" href="#simple-gstreamer-examples" title="Permalink to this heading">¶</a></h2>
<p>By default, all the example scripts use the filesink plug-in and write the output files into the /tmp directory.</p>
<p>Some of the examples read or write RAW files from disk (encode-only or decode-only pipelines). There is a chance that due to the massive bandwidth required for operating on these RAW files, you will notice a drop in FPS; this is not due to the Xilinx Video SDK but the disk speeds. We recommend reading/writing from <code class="docutils literal notranslate"><span class="pre">/dev/shm</span></code> which is a RAM disk.</p>
<p>Most of the scripts also have provision to use the fakesink plug-in which only displays performance numbers and will not write outputs to disk. This is done by setting the “fakesink” argument to 1.</p>
<p>Each script contains error checks before passing arguments to GStreamer pipeline command to help users avoid giving incorrect arguments.</p>
<p>Most of the example scripts included in this directory take H.264 input streams. To use H.265 input streams, update the scripts to use the <code class="docutils literal notranslate"><span class="pre">h265parse</span></code> GStreamer plug-in instead of <code class="docutils literal notranslate"><span class="pre">h264parse</span></code>.</p>
<p>For brevity purposes, explanations of the GStreamer element properties are not repeated after they have been explained once. The detailed explanation of the each GStreamer pipeline element property can be obtained by using <code class="docutils literal notranslate"><span class="pre">gst-inspect-1.0</span> <span class="pre">&lt;element</span> <span class="pre">name&gt;</span></code> (e.g. <code class="docutils literal notranslate"><span class="pre">gst-inspect-1.0</span> <span class="pre">vvas_xvcudec</span></code>).</p>
<section id="decode-only">
<span id="gstreamer-decode-only"></span><h3><a class="toc-backref" href="#id3">Decode only</a><a class="headerlink" href="#decode-only" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/01_gst_decode_only.sh">examples/gstreamer/tutorials/01_gst_decode_only.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./01_gst_decode_only.sh &lt;device index&gt; &lt;1080p60 H.264 file 8-bit/10-bit&gt; &lt;Number of decoder instances, 1 to 8&gt; &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; : On which device the pipeline should run
&lt;1080p60 H264 file&gt; : Input file location of 8-bit/10-bit
&lt;num instances, 1 to 8&gt; : Number of instances of the same pipeline to be run
&lt;Number of buffers&gt; : Num of Buffers to be processed. Useful to specify if we want to process small portion of bigger input stream. ``-1`` will run the complete video stream
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example accepts a clip that is already encoded in H.264 and will decode it using vvas_xvcudec plugin into a raw NV12 format. The raw file is saved to disk at /tmp/xil_dec_out_*.nv12 or /tmp/xil_dec_out_*.nv12_10le32 based on 8-bit or 10-bit input encoded stream. To get more understanding of the vvas_xvcudec plug-in properties, refer to the <a class="reference internal" href="../../using_gstreamer.html#gst-decoder-plugin"><span class="std std-ref">Decoder Plug-in</span></a> section of the GStreamer reference guide.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./01_gst_decode_only.sh 0 ~/videos/Test_1080p60.h264 1 -1 0

gst-launch-1.0 -v filesrc num-buffers=-1 location=~/videos/Test_1080p60.h264 \
! h264parse \
! vvas_xvcudec dev-idx=0 \
! fpsdisplaysink name=fpsdisplaysink_0 video-sink=&quot;filesink location=/tmp/xil_dec_out_1920x1080_8_0.nv12&quot; text-overlay=false sync=false
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gst-launch-1.0</span></code></p>
<ul>
<li><p>The GStreamer application, which is provided by Xilinx, and moved to the top of the PATH when you sourced the setup.sh script</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">filesrc</span> <span class="pre">location</span></code></p>
<ul>
<li><p>Location of the file to read</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">filesrc</span> <span class="pre">num-buffers</span></code></p>
<ul>
<li><p>Number of 4K sized buffers to be read from the input stream. Giving “-1” to this argument will read complete stream</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">h264parse</span></code></p>
<ul>
<li><p>Parses H.264 streams</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcudec</span></code></p>
<ul>
<li><p>GStreamer plug-in that provides functionality to decode H.264/H.265 encoded streams using Xilinx VCU decoder for PCIe platforms. This plug-in accepts input encoded stream in byte-stream/NALU format only and produces NV12 frames.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcudec</span> <span class="pre">dev-idx=&lt;device</span> <span class="pre">id&gt;</span></code> : Device on which the VCU decoder to be run.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">fpsdisplaysink</span></code></p>
<ul>
<li><p>Can display the current and average frame rate as a testoverlay or on stdout.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fpsdisplaysink</span> <span class="pre">video-sink=fakesink</span></code> : Video sink to use. It can be <cite>fakesink</cite>. It is a dummy sink that swallows everything and used to showcase maximum performance capability of the pipeline.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fpsdisplaysink</span> <span class="pre">video-sink=&quot;filesink</span> <span class="pre">location=/tmp/xil_dec_out_1920x1080_8_0.nv12&quot;</span></code> : Video sink to use. It can be <cite>filesink</cite>. It writes incoming data to a file in the local file system.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fpsdisplaysink</span> <span class="pre">text-overlay=&lt;true/false&gt;</span></code> : Whether to use text-overlay. Enabling this will display rendered frames data. For performance mode, this has to be set to false.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fpsdisplaysink</span> <span class="pre">sync=&lt;true/false&gt;</span></code> : Sync on the clock. For performance mode, this has to be set to false. Enabling this may lower the performance or drop the frames to match with the input video stream fps value</p></li>
</ul>
</li>
</ul>
</section>
<section id="encode-only">
<span id="gstreamer-encode-only"></span><h3><a class="toc-backref" href="#id4">Encode only</a><a class="headerlink" href="#encode-only" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/02_gst_h264_encode_only_1080p.sh">examples/gstreamer/tutorials/02_gst_h264_encode_only_1080p.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./02_gst_h264_encode_only_1080p.sh &lt;device index&gt; &lt;Input 1080p60 NV12 file&gt; &lt;Number of encoder instances, 1 to 4&gt; &lt;10bit-input 0/1&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; : On which device the pipeline should run
&lt;1080p60 H264 file&gt; : Input file location
&lt;num instances, 1 to 8&gt; : Number of instances of the same pipeline to be run
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example accepts a RAW 1080p60 clip in nv12/nv12-10le32 format. It will pass the clip to the encoder using vvas_xvcuenc plug-in to produce an H.264 encoded MP4 output with a target bitrate of 8Mbps and save it to disk at /tmp/xil_enc_out_*.mp4.</p>
<p>To get more understanding of the vvas_xvcudec plug-in properties, refer to the <a class="reference internal" href="../../using_gstreamer.html#gst-encoder-plugin"><span class="std std-ref">Encoder Plug-in</span></a> section of the GStreamer reference guide.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./02_gst_h264_encode_only_1080p.sh 0 ~/videos/Test_1080p60.nv12 1 0 0

gst-launch-1.0 filesrc location=~/videos/Test_1080p60.nv12 blocksize=3110400
! queue \
! rawvideoparse format=nv12 width=1920 height=1080 framerate=60/1 \
! vvas_xvcuenc dev-idx=0 target-bitrate=8000 max-bitrate=8000 enable-pipeline=true \
! h264parse \
! qtmux \
! fpsdisplaysink video-sink=&quot;filesink location=/tmp/xil_enc_out_0.mp4 &quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gst-launch-1.0</span></code></p>
<ul>
<li><p>The GStreamer application, which is provided by Xilinx, and moved to the top of the PATH when you sourced the setup.sh script</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">filesrc</span> <span class="pre">location</span></code></p>
<ul>
<li><p>Location of the file to read</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">blocksize</span></code></p>
<ul>
<li><p>By default, <code class="docutils literal notranslate"><span class="pre">filesrc</span></code> reads data in blocks of 4096 bytes. The <code class="docutils literal notranslate"><span class="pre">blocksize</span></code> option is used to override this default and specify how many bytes of data should be read in one go. Reading data from file in small increments may impact performance. When reading raw data, it is recommended to set the <code class="docutils literal notranslate"><span class="pre">blocksize</span></code> to the frame size (in bytes) so that a full frame is read each time.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">queue</span></code></p>
<ul>
<li><p>The queue will create a new thread on the source pad to decouple the processing on sink and source pad. This element needed between any two processing elements of a GStreamer pipeline, e.g. between vvas_xabrscaler and vvas_xvcuenc</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">rawvideoparse</span></code></p>
<ul>
<li><p>This element parses incoming data as raw video frames and timestamps these.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rawvideoparse</span> <span class="pre">format</span></code> : Format of frames in raw stream. Supported values are 8-bit (nv12) or 10-bit (nv12-10e32)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rawvideoparse</span> <span class="pre">width</span></code> : Width of frames in raw stream</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rawvideoparse</span> <span class="pre">height</span></code> : Height of frames in raw stream</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rawvideoparse</span> <span class="pre">framerate</span></code> : Rate of frames in raw stream</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">h264parse</span></code></p>
<ul>
<li><p>Placed at the output of the encoder, this elements tells the encoder to output an H.264 stream</p></li>
<li><p>Used along the <code class="docutils literal notranslate"><span class="pre">video/x-h264</span></code> caps filter, this can be used to specify the encoding profile type (baseline/high/high-10), e.g. <code class="docutils literal notranslate"><span class="pre">h264parse</span> <span class="pre">!</span> <span class="pre">video/x-h264,</span> <span class="pre">profile=high</span></code></p></li>
<li><p>Specifying other profile type leads to unexpected behavior or incorrect output stream</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">qtmux</span></code></p>
<ul>
<li><p>This element muxes streams into QuickTime(qt) files. This is needed whenever we are writing the output file as .mp4 container format instead of elementary H.264/H.265 format. Please note that qtmux causes printing of lot of hex characters on console about header info. User can ignore them</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span></code></p>
<ul>
<li><p>GStreamer plug-in that provides functionality to encode the raw frames (nv12/nv12-10le32) using Xilinx VCU encoder for PCIe platforms.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">dev-idx=&lt;device</span> <span class="pre">id&gt;</span></code> : Device on which to run the VCU encoder.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">target-bitrate=8000</span></code> : Target bit rate of the encoded stream in Kbps. 8000 signifies a target bit rate of 8 Megabits per second. This Value should be &lt;= max-bitrate</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">max-bitrate=8000</span></code> : Max bit rate in Kbps, only used if control-rate=variable</p></li>
</ul>
</li>
</ul>
</section>
<section id="basic-transcode">
<span id="gstreamer-basic-transcode"></span><h3><a class="toc-backref" href="#id5">Basic Transcode</a><a class="headerlink" href="#basic-transcode" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/03_gst_h264_transcode_only.sh">examples/gstreamer/tutorials/03_gst_h264_transcode_only.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./03_gst_h264_transcode_only.sh &lt;device index&gt; &lt;Input H.264 file&gt; &lt;Number of transcode instances, 1 to 8&gt; &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;Input H264 file&gt; : Input file location
&lt;num instances, 1 to 8&gt; : Number of instances of the same pipeline
&lt;Number of buffers&gt; : Num of Buffers to be processed. Useful to specify if we want to process small portion of bigger input stream. ``-1`` will run the complete video stream
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example demonstrates how to achieve simple transcoding, i.e. It takes an H.264 clip and re encodes it to H.264 with a new bit rate of 8Mbps. The output is written into <code class="file docutils literal notranslate"><span class="pre">/tmp/xil_xcode_*.mp4</span></code>. Input H.264 stream, from file source is decoded using hardware decoder and then re-encoded using vcu hardware encoder to H.264 format with same or different bit rate.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./03_gst_h264_transcode_only.sh  0 ~/videos/Test_1080p60.h264 1 -1 0

gst-launch-1.0 -v filesrc num-buffers=-1 location=~/videos/Test_1080p60.h264 \
! h264parse \
! vvas_xvcudec dev-idx=0 \
! queue \
! vvas_xvcuenc dev-idx=0 target-bitrate=8000 max-bitrate=8000 \
! h264parse \
! qtmux \
! fpsdisplaysink name=fpsdisplaysink_0 video-sink=&quot;filesink location=/tmp/xil_xcode_out_0.mp4&quot; text-overlay=false sync=false
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<p>Refer to the <a class="reference internal" href="#gstreamer-encode-only"><span class="std std-ref">Encode Only</span></a> and <a class="reference internal" href="#gstreamer-decode-only"><span class="std std-ref">Decode Only</span></a> examples descriptions for an illustration of the elements used in this pipeline.</p>
</section>
<section id="decode-only-into-multiple-resolution-outputs">
<span id="gstreamer-decode-and-scale"></span><h3><a class="toc-backref" href="#id6">Decode only into Multiple-Resolution outputs</a><a class="headerlink" href="#decode-only-into-multiple-resolution-outputs" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/04_gst_decode_plus_scale.sh">examples/gstreamer/tutorials/04_gst_decode_plus_scale.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./04_gst_decode_plus_scale.sh &lt;device index&gt; &lt;Input 1080p60 H264 file&gt; &lt;num instances, 1 to 4&gt; &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;Input 1080p60 H264 file&gt; : Input file location
&lt;num instances, 1 to 4&gt; : Number of instances of the same pipeline
&lt;Number of buffers&gt; : Number of buffers to be processed, Useful to specify if we want to use small portion of bigger stream. ``-1`` will run the complete video stream
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example decodes an existing 8-bit/10-bit H.264 file and then scales it into multiple resolutions as defined below. It will not re-encode them, but save the RAW outputs to disk under /tmp/xil_dec_scal*.nv12 or /tmp/xil_dec_scal*.nv12_10le32.</p>
<p>The 1080p60 input is scaled down to the following resolutions and frame rates (respectively): 720p60, 720p30, 480p30, 360p30, 288p30. <code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span></code> generates multiple resolution outputs. <code class="docutils literal notranslate"><span class="pre">tee</span></code> is used along with <code class="docutils literal notranslate"><span class="pre">videorate</span></code> to generate outputs with same resolution but with different frame rate.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./04_gst_decode_plus_scale.sh  0 ~/videos/Test_1080p60.h264 1 2000 0

gst-launch-1.0 filesrc num-buffers=2000 location=/home/siva/videos/Test_1080p60.h264 ! h264parse \
! vvas_xvcudec dev-idx=0 \
! queue \
! vvas_xabrscaler dev-idx=0 ppc=4 scale-mode=2 name=sc_00 \
sc_00.src_0 \
  ! queue ! video/x-raw, width=1280, height=720 \
  ! tee name=tee_00 \
  tee_00. \
    ! queue \
    ! videorate ! video/x-raw, framerate=60/1 \
    ! fpsdisplaysink name=sink_dec_scale_720p60_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_dec_scale_720p60_dev_8_0_0.nv12&quot; text-overlay=false sync=false \
  tee_00. \
    ! queue \
    ! videorate \
    ! video/x-raw, framerate=30/1 \
    ! fpsdisplaysink name=sink_dec_scale_720p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_dec_scale_720p30_dev_8_0_0.nv12&quot; text-overlay=false sync=false \
sc_00.src_1 \
    ! queue \
    ! video/x-raw, width=848, height=480 \
    ! videorate ! video/x-raw, framerate=30/1 \
    ! fpsdisplaysink name=sink_dec_scale_480p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_dec_scale_480p30_dev_8_0_0.nv12&quot; text-overlay=false sync=false \
sc_00.src_2 \
   ! queue \
   ! video/x-raw, width=640, height=360 \
   ! videorate ! video/x-raw, framerate=30/1 \
   ! fpsdisplaysink name=sink_dec_scale_360p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_dec_scale_360p30_dev_8_0_0.nv12&quot; text-overlay=false sync=false \
sc_00.src_3 \
   ! queue \
   ! video/x-raw, width=288, height=160 \
   ! videorate ! video/x-raw, framerate=30/1 \
   ! fpsdisplaysink name=sink_dec_scale_160p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_dec_scale_160p30_dev_8_0_0.nv12&quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span></code></p>
<ul>
<li><p>GStreamer plug-in developed to accelerate the resize and color space conversion functionality using Xilinx Multiscaler hardware kernel. Based on the <cite>video/x-raw</cite> caps of down stream element properties, this plug-in decides the color conversion format of the output stream. Currently the hardware kernel is supporting NV12 and NV12_10LE32 color formats and hence no other color format can be used. For resizing, any resolution with in 3840x2160 is supported provided that: width x height &lt;= 3840x2160, max width &lt;= 3840 and max height &lt;= 3840.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span> <span class="pre">dev-idx=&lt;device</span> <span class="pre">id&gt;</span></code> : Device on which the resize and color space conversion to be run.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span> <span class="pre">ppc=4</span></code> : Pixel per clock configuration for the multiscaler kernel. The only valid value is 4.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span> <span class="pre">scale-mode=2</span></code> : Scale Mode configuration for the multiscaler kernel. The only valid value is 2 (polyphase mode).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span> <span class="pre">name=&lt;sc_00&gt;</span></code> : The name of the object. Scaler supports single input stream to multiple output streams after resize or color conversion. There can be multiple down stream elements using these multiple outputs. Hence we need an object name of the scaler element that can be referenced by down stream elements. The <cite>.src_0</cite>, <cite>.src_1</cite>,.., are the source pad elements of the scaler object. Hence, each output of the scaler is referred as <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;.src_0</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;.src_1</span></code>, so on. In above example they are <code class="docutils literal notranslate"><span class="pre">sc_00.src_0</span></code>, <code class="docutils literal notranslate"><span class="pre">sc_00.src_1</span></code>, <code class="docutils literal notranslate"><span class="pre">sc_00.src_2</span></code>, so on. If there are more up stream elements, we can create multiple objects of the scaler (sc_00, sc_01, sc_02, ..) with each object has the multiple source pads.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">tee</span></code></p>
<ul>
<li><p>Split data to multiple pads. Branching the data flow is useful when e.g. capturing a video where the video is shown on the screen and also encoded and written to a file. One needs to use separate queue elements (or a multiqueue) in each branch to provide separate threads for each branch. Otherwise a blocked dataflow in one branch would stall the other branches. In above example <cite>tee</cite> along with <cite>videorate</cite> is used to generate 720p60 and 720p30 outputs from 720p60 input.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">videorate</span></code></p>
<ul>
<li><p>This element takes an incoming stream of timestamped video frames. It will produce a perfect stream that matches the source pad’s framerate.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">video/x-raw,</span> <span class="pre">width=&lt;&gt;,</span> <span class="pre">height=&lt;&gt;</span></code></p>
<ul>
<li><p>This is the source or sink pad capabilities by which the upstream or downstream element negotiates and works accordingly. Based on the capabilities of the GStreamer elements, if the pad capabilities are not matching, the pipeline fails with negotiation errors.</p></li>
</ul>
</li>
</ul>
</section>
<section id="encode-only-into-multiple-resolution-outputs">
<span id="gstreamer-encode-and-scale"></span><h3><a class="toc-backref" href="#id7">Encode only into Multiple-Resolution outputs</a><a class="headerlink" href="#encode-only-into-multiple-resolution-outputs" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/05_gst_encode_plus_scale_1080p.sh">examples/gstreamer/tutorials/05_gst_encode_plus_scale_1080p.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./05_gst_encode_plus_scale_1080p.sh &lt;device index&gt; &lt;1080p60 nv12 RAW file&gt; &lt;num instances, 1 to 4&gt; &lt;10bitinput 0/1&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;Input 1080p60 nv12 file&gt; : Input file location
&lt;num instances, 1 to 4&gt; : Number of instances of the same pipeline
&lt;10bitinput 0/1&gt; : Is input raw file is 10-bit or 8-bit. Set 1 for 10-bit and set 0 for 8-bit
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example will take a 8-bit or 10-bit 1080p60 RAW NV12 file and scale it and encode it into the resolutions as defined below and save them to disk under /tmp/xil_scale_enc*.mp4.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./05_gst_encode_plus_scale_1080p.sh  0 ~/videos/Test_1080p60.nv12 1 0 0

gst-launch-1.0 filesrc location=~/videos/Test_1080p60.nv12 blocksize=3110400 \
! queue ! rawvideoparse format=nv12 width=1920 height=1080 framerate=60/1 \
! queue \
! vvas_xabrscaler dev-idx=0 ppc=4 scale-mode=2 name=sc_00 avoid-output-copy=true enable-pipeline=true \
sc_00.src_0 ! queue ! video/x-raw, width=1280, height=720 \
  ! queue ! tee name=tee_00 \
  tee_00. \
    ! queue ! videorate ! video/x-raw, framerate=60/1 \
    ! vvas_xvcuenc name=enc_720p60_dev0_0 dev-idx=0 target-bitrate=4000 max-bitrate=4000 \
    ! h264parse ! qtmux \
    ! fpsdisplaysink name=sink_scale_enc_720p60_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_scale_enc_720p60_dev__0_0.mp4&quot; text-overlay=false sync=false \
  tee_00. \
    ! queue ! videorate ! video/x-raw, framerate=30/1 \
    ! vvas_xvcuenc name=enc_720p30_dev0_0 dev-idx=0 target-bitrate=3000 max-bitrate=3000 \
    ! h264parse ! qtmux \
    ! fpsdisplaysink name=sink_scale_enc_720p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_scale_enc_720p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_1 ! queue ! video/x-raw, width=848, height=480 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_480p30_dev0_0 dev-idx=0 target-bitrate=2500 max-bitrate=2500 \
  ! h264parse ! qtmux \
  ! fpsdisplaysink name=sink_scale_enc_480p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_scale_enc_480p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_2 ! queue ! video/x-raw, width=640, height=360 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_360p30_dev0_0 dev-idx=0 target-bitrate=1250 max-bitrate=1250 \
  ! h264parse ! qtmux \
  ! fpsdisplaysink name=sink_scale_enc_360p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_scale_enc_360p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_3 ! queue ! video/x-raw, width=288, height=160 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_160p30_dev0_0 dev-idx=0 target-bitrate=625 max-bitrate=625 \
  ! h264parse ! qtmux \
  ! fpsdisplaysink name=sink_scale_enc_160p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_scale_enc_160p30_dev__0_0.mp4&quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<p>Refer to the <a class="reference internal" href="#gstreamer-decode-and-scale"><span class="std std-ref">Decode only into Multiple-Resolution outputs</span></a> example description for an illustration of the elements used in this pipeline.</p>
</section>
<section id="transcode-with-multiple-resolution-outputs">
<span id="gstreamer-transcode-and-scale"></span><h3><a class="toc-backref" href="#id8">Transcode with Multiple-Resolution outputs</a><a class="headerlink" href="#transcode-with-multiple-resolution-outputs" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/06_gst_transcode_plus_scale.sh">examples/gstreamer/tutorials/06_gst_transcode_plus_scale.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./06_gst_transcode_plus_scale.sh &lt;device index&gt; &lt;Input 1080p60 H264 File&gt; &lt;num instances, 1 to 4&gt; &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;Input 1080p60 H264 file&gt; : Input file location
&lt;num instances, 1 to 4&gt; : Number of instances of the same pipeline
&lt;Number of buffers&gt; : Number of buffers to be processed instead of complete video stream for quick test. Set this to -1 to process complete input stream
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example implements a complete transcoding pipeline on an 1080p60 H.264 input. It decodes the input stream, scales it down to different resolutions and frame rates, encodes each of the scaled streams to H.264 and saves them to disk under <code class="file docutils literal notranslate"><span class="pre">/tmp/xil_xcode_scale_&lt;resolution&gt;.mp4</span></code>.</p>
<p>The 1080p60 input is scaled down and encoded back to the following resolutions and framerates (respectively):
720p60, 720p30, 480p30, 360p30, 288p30.</p>
<p>The command included in the script doesn’t handle the audio channel of the input video. For an example of how to include audio in the output streams, refer to the example commented out at the bottom of the script and to the section of the documentation about <a class="reference internal" href="../../using_gstreamer.html#gst-mapping-audio-streams"><span class="std std-ref">Mapping Audio Streams</span></a>.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./06_gst_transcode_plus_scale.sh 0 bbb_sunflower_1080p_60fps_normal.mp4 1 2000 1


gst-launch-1.0 filesrc num-buffers=-1 location=~/videos/bbb_sunflower_1080p_60fps_normal.mp4 \
! qtdemux \
! queue ! h264parse \
! vvas_xvcudec dev-idx=0 \
! queue \
! vvas_xabrscaler dev-idx=0 ppc=4 scale-mode=2 avoid-output-copy=true name=sc_00 \
sc_00.src_0 ! queue ! video/x-raw, width=1280, height=720 \
  ! tee name=tee_00 \
  tee_00. \
    ! queue ! videorate ! video/x-raw, framerate=60/1 \
    ! vvas_xvcuenc name=enc_720p60_dev0_0 dev-idx=0 target-bitrate=4000 \
    ! h264parse ! qtmux \
    ! fpsdisplaysink name=sink_xcode_scale_720p60_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_xcode_scale_720p60_dev__0_0.mp4&quot; text-overlay=false sync=false \
  tee_00. \
    ! queue ! videorate ! video/x-raw, framerate=30/1 \
    ! vvas_xvcuenc name=enc_720p30_dev0_0 dev-idx=0 target-bitrate=3000 \
    ! h264parse ! qtmux \
    ! fpsdisplaysink name=sink_xcode_scale_720p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_xcode_scale_720p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_1 ! queue ! video/x-raw, width=848, height=480 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_480p30_dev0_0 dev-idx=0 target-bitrate=2500 \
  ! h264parse ! qtmux \
  ! fpsdisplaysink name=sink_xcode_scale_480p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_xcode_scale_480p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_2 ! queue ! video/x-raw, width=640, height=360 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_360p30_dev0_0 dev-idx=0 target-bitrate=1250 \
  ! h264parse ! qtmux \
  ! fpsdisplaysink name=sink_xcode_scale_360p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_xcode_scale_360p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_3 ! queue ! video/x-raw, width=288, height=160 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_160p30_dev0_0 dev-idx=0 target-bitrate=625 \
  ! h264parse ! qtmux \
  ! fpsdisplaysink name=sink_xcode_scale_160p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_xcode_scale_160p30_dev__0_0.mp4&quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">qtdemux</span></code></p>
<ul>
<li><p>This element demuxes a QuickTime (qt) file into raw or compressed audio and/or video streams. This is needed whenever we are decoding an input stream of container format type with H.264/H.265 elementary stream in it</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span> <span class="pre">avoid-output-copy=true</span></code></p>
<ul>
<li><p>Avoid output frames copy on all source pads of the scaler even when downstream does not support GstVideoMeta metadata. when <code class="docutils literal notranslate"><span class="pre">tee</span></code> element is used after scaler,</p></li>
</ul>
</li>
</ul>
<p>Refer to the <a class="reference internal" href="#gstreamer-decode-and-scale"><span class="std std-ref">Decode only into Multiple-Resolution outputs</span></a> example description for an illustration of the other elements used in this pipeline.</p>
</section>
<section id="lower-latency-transcode-with-multiple-resolution-outputs">
<span id="gstreamer-transcode-and-scale-low-latency"></span><h3><a class="toc-backref" href="#id9">Lower-Latency Transcode With Multiple-Resolution outputs</a><a class="headerlink" href="#lower-latency-transcode-with-multiple-resolution-outputs" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/07_gst_transcode_plus_scale_lowlatency.sh">examples/gstreamer/tutorials/07_gst_transcode_plus_scale_lowlatency.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./07_gst_transcode_plus_scale_lowlatency.sh &lt;device index&gt; &lt;Input 1080p60 H264 File&gt; &lt;num instances, 1 to 4&gt; &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;Input 1080p60 H264 file&gt; : Input file location of mp4 container with H.264 stream or elementaty H.264 stream
&lt;num instances, 1 to 4&gt; : Number of instances of the same pipeline
&lt;Number of buffers&gt; : Number of buffers to be processed instead of complete video stream for quick test. Set this to -1 to process complete input stream
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example is the same as #6, which is a full transcode pipeline (decode, scale, encode), saving the scaled outputs into the files <code class="file docutils literal notranslate"><span class="pre">/tmp/xil_ll_xcode_scale_&lt;reso&gt;.mp4</span></code>. This differs in that is a “low latency” version, which removes the B-frames, and reduces the lookahead. Thus it decreases the latency at the cost of visual quality. This example will output corrupt data if you provide an input file that contains B-Frames.</p>
<p>This example will output corrupt data if you provide an input file that contains B-Frames.</p>
<p>The command included in the script doesn’t handle the audio channel of the input video. For an example of how to include audio in the output streams, refer to the example commented out at the bottom of the script and to the section of the documentation about <a class="reference internal" href="../../using_gstreamer.html#gst-mapping-audio-streams"><span class="std std-ref">Mapping Audio Streams</span></a>.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./07_gst_transcode_plus_scale_lowlatency.sh 0 bbb_sunflower_1080p_60fps_normal.mp4 1 2000 1

gst-launch-1.0 filesrc num-buffers=2000 location=/home/siva/videos/bbb_sunflower_1080p_60fps_normal.mp4 \
! qtdemux \
! queue \
! h264parse \
! vvas_xvcudec dev-idx=0 low-latency=1 \
! queue \
! vvas_xabrscaler dev-idx=0 ppc=4 scale-mode=2 avoid-output-copy=true name=sc_00 \
sc_00.src_0 ! queue ! video/x-raw, width=1280, height=720 \
  ! tee name=tee_00 \
  tee_00. \
    ! queue ! videorate ! video/x-raw, framerate=60/1 \
    ! vvas_xvcuenc name=enc_720p60_dev0_0 dev-idx=0 target-bitrate=4000 b-frames=0 scaling-list=0 \
    ! h264parse \
    ! qtmux \
    ! fpsdisplaysink name=sink_ll_xcode_scale_720p60_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_ll_xcode_scale_720p60_dev__0_0.mp4&quot; text-overlay=false sync=false \
  tee_00. \
    ! queue ! videorate ! video/x-raw, framerate=30/1 \
    ! vvas_xvcuenc name=enc_720p30_dev0_0 dev-idx=0 target-bitrate=3000 b-frames=0 scaling-list=0 \
    ! h264parse \
    ! qtmux \
    ! fpsdisplaysink name=sink_ll_xcode_scale_720p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_ll_xcode_scale_720p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_1 ! queue ! video/x-raw, width=848, height=480 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_480p30_dev0_0 dev-idx=0 target-bitrate=2500 b-frames=0 scaling-list=0 \
  ! h264parse \
  ! qtmux \
  ! fpsdisplaysink name=sink_ll_xcode_scale_480p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_ll_xcode_scale_480p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_2 ! queue ! video/x-raw, width=640, height=360 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_360p30_dev0_0 dev-idx=0 target-bitrate=1250 b-frames=0 scaling-list=0 \
  ! h264parse \
  ! qtmux \
  ! fpsdisplaysink name=sink_ll_xcode_scale_360p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_ll_xcode_scale_360p30_dev__0_0.mp4&quot; text-overlay=false sync=false \
sc_00.src_3 ! queue ! video/x-raw, width=288, height=160 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_160p30_dev0_0 dev-idx=0 target-bitrate=625 b-frames=0 scaling-list=0 \
  ! h264parse \
  ! qtmux \
  ! fpsdisplaysink name=sink_ll_xcode_scale_160p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_ll_xcode_scale_160p30_dev__0_0.mp4&quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcudec</span> <span class="pre">low-latency=1</span></code></p>
<ul>
<li><p>This flag disables the Decoder’s ability to handle out-of-order frames (i.e. B-Frames). Decoding I and P frames only decreases the latency of the system.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xabrscaler</span> <span class="pre">avoid-output-copy=true</span></code></p>
<ul>
<li><p>Avoid output frames copy on all source pads even when downstream does not support GstVideoMeta metadata</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">b-frames=0</span></code></p>
<ul>
<li><p>Number of B-frames between two consecutive P-frames. The number of b-frames inserted in the output stream not only increases encode latency in the Xilinx device, but decode latency on the player. Setting it to 0 removes them.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">scaling-list=0</span></code></p>
<ul>
<li><p>Scaling list mode. Value <cite>0</cite> indiactes Flat scaling list mode. Disables the scaling list, which is a pre-encode processing which normally adds to the latency of the pipeline.</p></li>
</ul>
</li>
</ul>
<p>Refer to the <a class="reference internal" href="#gstreamer-decode-and-scale"><span class="std std-ref">Decode only into Multiple-Resolution outputs</span></a> example description for an illustration of the elements used in this pipeline.</p>
</section>
</section>
<section id="encoding-streams-to-4k">
<h2><a class="toc-backref" href="#id10">Encoding Streams to 4K</a><a class="headerlink" href="#encoding-streams-to-4k" title="Permalink to this heading">¶</a></h2>
<p>The Xilinx Video SDK supports real-time decoding and encoding of 4k streams with the following notes:</p>
<ul class="simple">
<li><p>The Xilinx video pipeline is optimized for live-streaming use cases. For 4k streams with bitrates significantly higher than the ones typically used for live streaming, it may not be possible to sustain real-time performance.</p></li>
<li><p>When decoding 4k streams with a high bitrate, increasing the number of entropy buffers using the <a class="reference internal" href="../../using_ffmpeg.html#cmdoption-entropy_buffers_count"><code class="xref std std-option docutils literal notranslate"><span class="pre">-entropy_buffers_count</span></code></a> option can help improve performance</p></li>
<li><p>When encoding raw video to 4k, set the <cite>width and height</cite> parameters to <code class="docutils literal notranslate"><span class="pre">3840</span> <span class="pre">and</span> <span class="pre">2160</span></code> to specify the desired resolution.</p></li>
<li><p>When encoding 4k streams to H.264, the <a class="reference internal" href="../../using_gstreamer.html#cmdoption-arg-num-slices"><code class="xref std std-option docutils literal notranslate"><span class="pre">num-slices</span></code></a> option is required to sustain real-time performance. A value of 4 is recommended. This option is not required when encoding to HEVC.</p></li>
</ul>
<section id="k-h-264-real-time-encode-only">
<h3><a class="toc-backref" href="#id11">4K H.264 Real-Time Encode Only</a><a class="headerlink" href="#k-h-264-real-time-encode-only" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/08_gst_encode_only_4k.sh">examples/gstreamer/tutorials/08_gst_encode_only_4k.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./08_gst_encode_only_4k.sh &lt;Device Index&gt; &lt;raw 4K nv12 file&gt; &lt;Number of encode instances, 1&gt; &lt;10bitinput 0/1&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;raw 4K nv12 file&gt; : Input file location of raw 4K 8-bit/10-bit file
&lt;num instances, 1&gt; : Number of instances are fixed to 1 as each device can support a max of 4K60
&lt;10bitinput 0/1&gt; : Input raw file is of 10-bit (value 1) or 8-bit type (value 0). For encoder scripts, the user must set this option.
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example takes an 8-bit, 2160p60 RAW file of 8-bit (NV12) or 10-bit (NV12_10LE32), encodes it to H.264 at a rate of 20Mbps and writes the result into <code class="file docutils literal notranslate"><span class="pre">/tmp/xil_4k_enc_out.mp4</span></code>. The <a class="reference internal" href="../../using_gstreamer.html#cmdoption-arg-num-slices"><code class="xref std std-option docutils literal notranslate"><span class="pre">num-slices</span></code></a> option is required to sustain real-time performance when encoding a 4k stream to H.264.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./08_gst_encode_only_4k.sh 0 ~/videos/test4K.nv12 1 0 0

gst-launch-1.0 filesrc location=test4K.nv12 blocksize=12441600 \
! queue \
! rawvideoparse format=nv12 width=3840 height=2160 framerate=60/1 \
! vvas_xvcuenc dev-idx=0 target-bitrate=20000 max-bitrate=20000 num-slices=4 enable-pipeline=true \
! h264parse \
! qtmux \
! fpsdisplaysink video-sink=&quot;filesink location=/tmp/xil_4k_enc_out_0.mp4 &quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcudec</span> <span class="pre">num-slices=4</span></code></p>
<ul>
<li><p>Number of slices produced for each frame. This option is required to sustain real-time performance when encoding a 4k stream to H.264.</p></li>
</ul>
</li>
</ul>
</section>
<section id="k-h-264-real-time-transcode">
<h3><a class="toc-backref" href="#id12">4K H.264 Real-Time Transcode</a><a class="headerlink" href="#k-h-264-real-time-transcode" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/09_gst_transcode_only_4k.sh">examples/gstreamer/tutorials/09_gst_transcode_only_4k.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./09_gst_transcode_only_4k.sh &lt;Device Index&gt; &lt;Input 4K H265/HEVC file&gt; &lt;Number of transcode instances, 1&gt;  &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;

&lt;device index&gt; :  On which device the pipeline should run
&lt;Input 4K H.265/HEVC fil&gt; : Input file location of H.265 encoded stream
&lt;num instances, 1&gt; : Number of instances are fixed to 1 as each device can support a max of 4K60
&lt;fakesink 0/1&gt; : Whether to write the output to fakesink (for performance) or to write the output stream to a location on the disk
</pre></div>
</div>
<p>This example takes an 2160p60 HEVC file, transcodes it to H.264 at a rate of 20Mbps and writes the result into <code class="file docutils literal notranslate"><span class="pre">/tmp/xil_xcode_*.mp4</span></code>. The <a class="reference internal" href="../../using_gstreamer.html#cmdoption-arg-num-slices"><code class="xref std std-option docutils literal notranslate"><span class="pre">num-slices</span></code></a> option is required to sustain real-time performance when encoding a 4k stream to H.264.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./09_gst_transcode_only_4k.sh 0 ~/videos/Test_4k_60fps.h265 1 -1 0

gst-launch-1.0 filesrc location=~/videos/Test_4k_60fps.h265 \
! h265parse \
! vvas_xvcudec num-entropy-buf=3 dev-idx=0 \
! vvas_xvcuenc dev-idx=0 b-frames=2 target-bitrate=20000 max-bitrate=20000 prefetch-buffer=true num-slices=4 gop-mode=low-delay-p control-rate=2 \
! h264parse \
! qtmux \
! fpsdisplaysink video-sink=&quot;filesink location=/tmp/xil_xcode_4k_0.mp4 &quot; text-overlay=false sync=false -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">prefetch-buffer=true</span></code></p>
<ul class="simple">
<li><p>Enable/Disable L2Cache buffer in encoding process.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">gop-mode=low-delay-p</span></code></p>
<ul class="simple">
<li><p>Group Of Pictures mode. Setting it to <cite>low-delay-p</cite> gop-mode is set to Single I-frame followed by P-frames only</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vvas_xvcuenc</span> <span class="pre">control-rate=2</span></code></p>
<ul class="simple">
<li><p>Bitrate control method. It is set to <code class="docutils literal notranslate"><span class="pre">Constant</span></code> mode.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">h265parse</span></code></p>
<ul class="simple">
<li><p>Placed at the output of the encoder, this elements tells the encoder to output an H.265 stream</p></li>
<li><p>Used along the <code class="docutils literal notranslate"><span class="pre">video/x-h265</span></code> caps filter, this can be used to specify the encoding profile type (main/main-10), e.g. <code class="docutils literal notranslate"><span class="pre">h265parse</span> <span class="pre">!</span> <span class="pre">video/x-h265,</span> <span class="pre">profile=main</span></code></p></li>
<li><p>Specifying other profile type leads to unexpected behavior or incorrect output stream</p></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
</li>
</ul>
</section>
</section>
<section id="running-on-multiple-devices">
<span id="gstreamer-device-id-examples"></span><h2><a class="toc-backref" href="#id13">Running on Multiple Devices</a><a class="headerlink" href="#running-on-multiple-devices" title="Permalink to this heading">¶</a></h2>
<p>So far we’ve run one job at a time, even if the job does not use all the resources available on the device. The Video SDK makes it possible to run multiple GStreamer jobs in parallel on a device or across multiple devices.</p>
<p>This script transcodes three H.264 streams to HEVC, sending the outputs to /tmp/xil_xcode_{n}.mp4. The three transcodes are run in parallel in individual xterms. The GStreamer <a class="reference internal" href="../../using_gstreamer.html#cmdoption-arg-dev-idx"><code class="xref std std-option docutils literal notranslate"><span class="pre">dev-idx</span></code></a> option is used to control on which device each job is run. The first job is run on device #0 and the two others jobs are run on device #1. After the jobs are launched, a JSON system load report is generated. Ensure that “xbutil list” shows at least 2 devices before running this program.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This example leverages the <code class="docutils literal notranslate"><span class="pre">xterm</span></code> program. Make sure it is installed on your system before proceeding.</p>
</div>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/10_gst_multiple_jobs.sh">examples/gstreamer/tutorials/10_gst_multiple_jobs.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./10_gst_multiple_jobs.sh &lt;input_h264_1_mp4&gt; &lt;input_h264_2_mp4&gt; &lt;input_h264_3_mp4&gt;
</pre></div>
</div>
<p><strong>commands</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Launch the three jobs in parallel
xterm -fa mono:size=9 -hold -e &quot;gst-launch-1.0 filesrc location=$1 ! qtdemux ! queue ! h264parse ! vvas_xvcudec  dev-idx=0 ! vvas_xvcuenc dev-idx=0 target-bitrate=2000 ! h265parse ! video/x-h265 ! qtmux ! fpsdisplaysink video-sink=&quot;filesink location=/tmp/xil_xcode_1.mp4&quot; text-overlay=false sync=false -v&quot;
xterm -fa mono:size=9 -hold -e &quot;gst-launch-1.0 filesrc location=$2 ! qtdemux ! queue ! h264parse ! vvas_xvcudec  dev-idx=0 ! vvas_xvcuenc dev-idx=0 target-bitrate=2000 ! h265parse ! video/x-h265 ! qtmux ! fpsdisplaysink video-sink=&quot;filesink location=/tmp/xil_xcode_2.mp4&quot; text-overlay=false sync=false -v&quot;
xterm -fa mono:size=9 -hold -e &quot;gst-launch-1.0 filesrc location=$3 ! qtdemux ! queue ! h264parse ! vvas_xvcudec  dev-idx=0 ! vvas_xvcuenc dev-idx=0 target-bitrate=2000 ! h265parse ! video/x-h265 ! qtmux ! fpsdisplaysink video-sink=&quot;filesink location=/tmp/xil_xcode_3.mp4&quot; text-overlay=false sync=false -v&quot;

# Wait until the jobs are started to generate a system load report
sleep 2s
xrmadm /opt/xilinx/xrm/test/list_cmd.json &amp;
</pre></div>
</div>
<p><strong>Tutorial steps</strong></p>
<ul>
<li><p>Prepare 3 input H.264 videos with the following resolutions: 4k60, 1080p60 and 720p30</p></li>
<li><p>Confirm there are a least two devices available in your system:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>xbutil examine
</pre></div>
</div>
</li>
<li><p>Run the example script with the 3 input videos:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./10_gst_multiple_jobs.sh 4k60.mp4 1080p60.mp4 720p30.mp4
</pre></div>
</div>
</li>
<li><p>The script opens three xterm windows and runs a transcode job in each of them. After 2 seconds, to ensure all jobs are running, the script executes the <code class="docutils literal notranslate"><span class="pre">xrmadm</span> <span class="pre">/opt/xilinx/xrm/test/list_cmd.json</span></code> command to generate a report of the system load.</p></li>
<li><p>In each of the xterm windows, inspect the GStreamer transcript and observe that it indicates on which device the job is run:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>device_id   :  0
</pre></div>
</div>
</li>
<li><p>Inspect the system load report (in JSON format) in the main terminal. For each device, the loading percentage is reported in the <code class="docutils literal notranslate"><span class="pre">usedLoad</span></code> field for each of the decoder, scaler, and encoder compute units. A value of 0 indicates that a particular resources is completely free. A value of 1000000 indicates that a particular resource is fully loaded and can no longer accept jobs. In the example shown below, the decoder is 25% utilized and can therefore accept more jobs.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;cu_3&quot;: {
    &quot;cuId         &quot;: &quot;3&quot;,
    &quot;cuType       &quot;: &quot;IP Kernel&quot;,
    &quot;kernelName   &quot;: &quot;decoder&quot;,
    &quot;kernelAlias  &quot;: &quot;DECODER_MPSOC&quot;,
    &quot;instanceName &quot;: &quot;decoder_1&quot;,
    &quot;cuName       &quot;: &quot;decoder:decoder_1&quot;,
    &quot;kernelPlugin &quot;: &quot;/opt/xilinx/xma_plugins/libvcu-xma-dec-plg.so&quot;,
    &quot;maxCapacity  &quot;: &quot;497664000&quot;,
    &quot;numChanInuse &quot;: &quot;1&quot;,
    &quot;usedLoad     &quot;: &quot;250000 of 1000000&quot;,
    &quot;reservedLoad &quot;: &quot;0 of 1000000&quot;,
    &quot;resrvUsedLoad&quot;: &quot;0 of 1000000&quot;
}
</pre></div>
</div>
</li>
<li><p>Close the three xterm windows</p></li>
<li><p>Now rerun the script with the input files in a different order:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./10_gst_multiple_jobs.sh 720p30.mp4 4k60.mp4 1080p60.mp4
</pre></div>
</div>
<p>This will try to simultaneously run the 4k60 and the 1080p60 jobs on device #1. The compute requirements of these two combined jobs will exceed the capacity of a single device. Only one of the two jobs will proceed and the second one will error out due to insufficient resources.</p>
</li>
</ul>
<section id="running-multiple-jobs-using-the-vvas-xabrladder-application">
<h3><a class="toc-backref" href="#id14">Running Multiple Jobs using the vvas_xabrladder Application</a><a class="headerlink" href="#running-multiple-jobs-using-the-vvas-xabrladder-application" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/14_gst_app_transcode_plus_scale.sh">examples/gstreamer/tutorials/14_gst_app_transcode_plus_scale.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./14_gst_app_transcode_plus_scale.sh &lt;device index&gt; &lt;Input 1080p60 MP4 file with H.264 content&gt;
</pre></div>
</div>
<p>This script calls four processes of vvas_xabrladder application simultaneously. vvas_xabrladder is a command line utility that implements the GStreamer video transcoding pipeline. This application expects an input video file (mp4 with H.264/H.265 or H.264/H.265 elementary stream) and produces 5 different H.264/H.265 elementary streams based on codec type provided. The output files are stored at /tmp/ladder_outputs directory. More documentation on vvas_xabrladder can be found at <a class="reference internal" href="xabrladder.html#gst-abrladder"><span class="std std-ref">GStreamer ABR Ladder Application</span></a></p>
<p><strong>commands</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./14_gst_app_transcode_plus_scale.sh 0 bbb_sunflower_1080p_60fps_normal.mp4
</pre></div>
</div>
</section>
<section id="transcode-with-lookahead-for-multiple-resolution-outputs">
<span id="gstreamer-lookahead-and-scale"></span><h3><a class="toc-backref" href="#id15">Transcode with lookahead for Multiple-Resolution outputs</a><a class="headerlink" href="#transcode-with-lookahead-for-multiple-resolution-outputs" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/15_gst_transcode_plus_scale_la.sh">examples/gstreamer/tutorials/15_gst_transcode_plus_scale_la.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./15_gst_transcode_plus_scale_la.sh &lt;device index&gt; &lt;Input MP4 file with H.264 content&gt; &lt;num instances, 1 to 4&gt; &lt;Number of buffers&gt; &lt;fakesink 0/1&gt;
</pre></div>
</div>
<p>This example will do a full transcode pipeline on an 1080p60 H.264 input, scale it into the resolutions below, and re-encode them, saving them in /tmp/sink_xcode_scale_*.h264. The raw output from scaler is padded through lookahead before going to encoder. Lookahead is used to improve the accuracy of rate control by enabling the encoder to buffer a specified number of frames (using the parameter). The 1080p60 input is scaled down and encoded back to the following resolutions and framerates (respectively):
720p60, 720p30, 480p30, 360p30, 288p30.</p>
<p><strong>commands</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. ./15_gst_transcode_plus_scale_la.sh 0 bbb_sunflower_1080p_60fps_normal.mp4 1 2000 0

gst-launch-1.0 filesrc num-buffers=2000 location=~/Videos/bbb_sunflower_1080p_60fps_normal.mp4 ! qtdemux ! queue ! h264parse ! vvas_xvcudec dev-idx=0 ! queue ! vvas_xabrscaler avoid-output-copy=true dev-idx=0 ppc=4 scale-mode=2 name=sc_00 sc_00.src_0 ! queue ! video/x-raw, width=1280, height=720 ! tee name=tee_00 tee_00. ! queue ! videorate ! video/x-raw, framerate=60/1 ! vvas_xlookahead codec-type=0 spatial-aq=1 temporal-aq=1 lookahead-depth=8 rc-mode=1 dev-idx=0 ! vvas_xvcuenc name=enc_720p60_dev0_0 dev-idx=0 target-bitrate=4000 rc-mode=1 ! h264parse ! qtmux ! fpsdisplaysink name=sink_xcode_scale_720p60_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_la_xcode_scale_720p60_dev__0_0.mp4 async=false&quot; text-overlay=false sync=false tee_00. ! queue ! videorate ! video/x-raw, framerate=30/1 ! vvas_xlookahead codec-type=0 spatial-aq=1 temporal-aq=1 lookahead-depth=8 rc-mode=1 dev-idx=0 ! vvas_xvcuenc name=enc_720p30_dev0_0 dev-idx=0 target-bitrate=3000 rc-mode=1 ! h264parse ! qtmux ! fpsdisplaysink name=sink_xcode_scale_720p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_la_xcode_scale_720p30_dev__0_0.mp4 async=false&quot; text-overlay=false sync=false sc_00.src_1 ! queue ! video/x-raw, width=848, height=480 ! videorate ! video/x-raw, framerate=30/1 ! vvas_xlookahead codec-type=0 spatial-aq=1 temporal-aq=1 lookahead-depth=8 rc-mode=1 dev-idx=0 ! vvas_xvcuenc name=enc_480p30_dev0_0 dev-idx=0 target-bitrate=2500 rc-mode=1 ! h264parse ! qtmux ! fpsdisplaysink name=sink_xcode_scale_480p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_la_xcode_scale_480p30_dev__0_0.mp4 async=false&quot; text-overlay=false sync=false sc_00.src_2 ! queue ! video/x-raw, width=640, height=360 ! videorate ! video/x-raw, framerate=30/1 ! vvas_xlookahead codec-type=0 spatial-aq=1 temporal-aq=1 lookahead-depth=8 rc-mode=1 dev-idx=0 ! vvas_xvcuenc name=enc_360p30_dev0_0 dev-idx=0 target-bitrate=1250 rc-mode=1 ! h264parse ! qtmux ! fpsdisplaysink name=sink_xcode_scale_360p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_la_xcode_scale_360p30_dev__0_0.mp4 async=false&quot; text-overlay=false sync=false sc_00.src_3 ! queue ! video/x-raw, width=288, height=160 ! videorate ! video/x-raw, framerate=30/1 ! vvas_xlookahead codec-type=0 spatial-aq=1 temporal-aq=1 lookahead-depth=8 rc-mode=1 dev-idx=0 ! vvas_xvcuenc name=enc_160p30_dev0_0 dev-idx=0 target-bitrate=625 rc-mode=1 ! h264parse ! qtmux ! fpsdisplaysink name=sink_xcode_scale_160p30_dev0_0 video-sink=&quot;filesink location=/\tmp/\xil_la_xcode_scale_160p30_dev__0_0.mp4 async=false&quot; text-overlay=false sync=false -v
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For any script that is being run for multiple instances, user should ensure that the resolution of input stream*number of instances is not beyond maximum hardware supported resolution i.e. 4K60. Failing this requirement, device may go to unknown state and host needs to be cold rebooted.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In a pipeline which handles 4K streams, set async=false on all sink elements (fakesink, filesink) to avoid pipeline hangs as queue elements gets filled with raw 4K frames quickly. In case user do not want to set async=false, they should be aware of queue elements full condition as per open source documentation</p>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
</section>
<section id="faster-than-real-time">
<span id="faster-than-realtime-gstreamer-example"></span><h2><a class="toc-backref" href="#id16">Faster than Real-Time</a><a class="headerlink" href="#faster-than-real-time" title="Permalink to this heading">¶</a></h2>
<p>Xilinx devices and the Xilinx Video SDK are optimized for low latency “real-time” applications. That is to say, they provide deterministic low latency transcoding, while operating at the FPS the human eye would normally process/watch it. This is ideal for ingesting a live video stream where there is minimal buffering.</p>
<p>When processing file-based video clips, it is possible to run faster than real time (FTRT) by using a map-reduce approach. With this method, the file-based video clip is split into multiple smaller segments, and each of these segments is individually transcoded. The more devices are available, the more segments can be processed in parallel and the faster the process is. While there is some overhead in “splitting” the clip into segments, and “stitching” the results of each segment into a single output file, these costs are almost always outweighed by the improvement in FPS.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">13_gst_transcode_only_split_stitch.py</span></code> python script starts by automatically detecting the number of devices available in the system and then determines how many jobs can be run on each device based on the resolution of the input file. The input file is then split in as many segments aligning on GOP boundaries. Parallel GStreamer jobs are submited to transcode all the segments simultaneously. The <a class="reference internal" href="../../using_gstreamer.html#cmdoption-arg-dev-idx"><code class="xref std std-option docutils literal notranslate"><span class="pre">dev-idx</span></code></a> option is used to dispatch each job on a specific device. Once all the segments have been processed, GStreamer is used to concatenate the results and form the final output stream.</p>
<p>This example script is provided for demonstration purposes. It is not intended to work for all input clips and all use cases.</p>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/13_gst_transcode_only_split_stitch.py">examples/gstreamer/tutorials/13_gst_transcode_only_split_stitch.py</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>python3 13_gst_transcode_only_split_stitch.py -s &lt;INPUT_FILE&gt; -d &lt;OUTPUT_FILE&gt; -c &lt;OUTPUT_CODEC&gt; -b &lt;BITRATE&gt;
</pre></div>
</div>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>e.g. python3 13_gst_transcode_only_split_stitch.py  -s ~/videos/bbb_sunflower_1080p_60fps_normal.mp4 -d ./output.mp4 -c h264 -b 5
</pre></div>
</div>
<p>Explanation of the flags:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">&lt;INPUT_FILE&gt;</span></code></p>
<ul>
<li><p>This is the name of the pre-encoded input file in MP4 format with h264 or h265 elementary stream.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">&lt;OUTPUT_FILE&gt;</span></code></p>
<ul>
<li><p>This is the name of the output file. The default output file name is “out.mp4”</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-c</span> <span class="pre">&lt;OUTPUT_CODEC&gt;</span></code></p>
<ul>
<li><p>This defines the desired output encoder format: supported formats are <code class="docutils literal notranslate"><span class="pre">h264</span></code>, <code class="docutils literal notranslate"><span class="pre">hevc</span></code>, and <code class="docutils literal notranslate"><span class="pre">h265</span></code>. Note that <code class="docutils literal notranslate"><span class="pre">h265</span></code> and <code class="docutils literal notranslate"><span class="pre">hevc</span></code> are identical; they are provided for ease of customer use. The default output codec is <code class="docutils literal notranslate"><span class="pre">hevc</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">&lt;BITRATE&gt;</span></code></p>
<ul>
<li><p>This is a float or integer value which defines the output file’s target bitrate in Mbits/s. Valid values are comprised between 1.0 and 25.0. The default value is 5.0. Example: use -b 3 to specify an output bitrate of 3Mbits/s.</p></li>
</ul>
</li>
</ul>
<p>In addition to the primary flags listed above, the script also supports the following optional flags:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-j</span> <span class="pre">&lt;NUM_JOBS&gt;</span></code></p>
<ul>
<li><p>Number of transcode jobs per device. By default the script estimates how many jobs can be run simultaneously on each device. Using this option allows to overwrite to number computed by the script.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-n</span> <span class="pre">&lt;NUM_DEVICES&gt;</span></code></p>
<ul>
<li><p>Number of devices on which to transcode the segments. By default the script will use all available devices. Using this options allows running the script on a subset of the available devices. For example, use <code class="docutils literal notranslate"><span class="pre">-n</span> <span class="pre">12</span></code> to run on 12 out of 16 available devices in a vt1.24xlarge instance.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-x</span> <span class="pre">&lt;ENCODE_OPTIONS&gt;</span></code></p>
<ul>
<li><p>Additional options for the encoder, specified as a string. For example, use <code class="docutils literal notranslate"><span class="pre">-x</span> <span class="pre">&quot;b-frames=1&quot;</span></code> to set the number of B frames to 1 in the output video. Bitrate values set with this options take precedence over values set with -b.</p></li>
</ul>
</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
<section id="streaming-examples">
<h2><a class="toc-backref" href="#id17">Streaming Examples</a><a class="headerlink" href="#streaming-examples" title="Permalink to this heading">¶</a></h2>
<p>Streaming Examples operate largely on the same principles (and command line strings) as file-based operations. However, the main difference is how streams are received and transmitted.</p>
<p>These examples is will leverage example #6, which is a full transcode pipeline (decode, scale, encode), however, instead of saving the scaled outputs into monolithic MP4 files, will create a “manifest” file <code class="docutils literal notranslate"><span class="pre">.m3u8</span></code> for streaming along with several <code class="docutils literal notranslate"><span class="pre">.ts</span></code> files with the actual playback data. These manifest files, when inspected, will contain a “playlist” of clips with <code class="docutils literal notranslate"><span class="pre">.ts</span></code> extensions, which are of duration <code class="docutils literal notranslate"><span class="pre">hls_time</span></code>. Creating separate clips enables the remote playback players to “drop quality” instantaneously without any buffering to the viewer, or trying to figure out and seek to “where we are in the clip”. This is how most live streaming is done, however there are other, similar protocols (e.g. DASH) which operate on similar principles.</p>
<section id="replay-saved-files-with-downscaling">
<h3><a class="toc-backref" href="#id18">Replay Saved Files with Downscaling</a><a class="headerlink" href="#replay-saved-files-with-downscaling" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Example script : <a class="reference external" href="https://github.com/Xilinx/video-sdk/blob/v2.0/examples/gstreamer/tutorials/12_gst_streaming_transcode_from_file.sh">examples/gstreamer/tutorials/12_gst_streaming_transcode_from_file.sh</a></p></li>
</ul>
<p><strong>Usage</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./12_gst_streaming_transcode_from_file.sh &lt;device index&gt; &lt;Input 1080p60 H.264 file&gt; &lt;[Number of buffers]&gt;
</pre></div>
</div>
<p>Ensure we have created and given write access to the <code class="docutils literal notranslate"><span class="pre">/var/www/html</span></code> directory before running this script.</p>
<p>The command included in the script doesn’t handle the audio channel of the input video. For an example of how to include audio in the output streams, refer to the example commented out at the bottom of the script and to the section of the documentation about <a class="reference internal" href="../../using_gstreamer.html#gst-mapping-audio-streams"><span class="std std-ref">Mapping Audio Streams</span></a>.</p>
<p><strong>Command Line</strong>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>gst-launch-1.0 filesrc num-buffers=2000 location=bbb_sunflower_1080p_60fps_normal.mp4 \
! qtdemux ! queue ! h264parse \
! vvas_xvcudec dev-idx=0 \
! queue \
! vvas_xabrscaler dev-idx=0 ppc=4 scale-mode=2 name=sc_00 avoid-output-copy=true \
sc_00.src_0 ! queue ! video/x-raw, width=1280, height=720, format=NV12 \
  ! tee name=tee_00 \
  tee_00. \
  ! queue ! videorate ! video/x-raw, framerate=60/1 \
  ! vvas_xvcuenc name=enc_720p60_dev0_0 dev-idx=0 target-bitrate=4000 \
  ! h264parse ! video/x-h264 \
  ! hlssink2 target-duration=4 playlist-length=5 max-files=5 location=/var/www/html/segment1_%05d.ts playlist-location=/var/www/html/xil_xcode_stream_scale_720p60.m3u8 \
  tee_00. \
  ! queue ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_720p30_dev0_0 dev-idx=0 target-bitrate=3000 \
  ! h264parse ! video/x-h264 \
  ! hlssink2 target-duration=4 playlist-length=5 max-files=5 location=/var/www/html/segment2_%05d.ts playlist-location=/var/www/html/xil_xcode_stream_scale_720p30.m3u8 \
sc_00.src_1 ! queue ! video/x-raw, width=848, height=480, format=NV12 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_480p30_dev0_0 dev-idx=0 target-bitrate=2500 \
  ! h264parse ! video/x-h264 \
  ! hlssink2 target-duration=4 playlist-length=5 max-files=5 location=/var/www/html/segment3_%05d.ts playlist-location=/var/www/html/xil_xcode_stream_scale_480p30.m3u8 \
sc_00.src_2 ! queue ! video/x-raw, width=640, height=360, format=NV12 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_360p30_dev0_0 dev-idx=0 target-bitrate=1250 \
  ! h264parse ! video/x-h264 \
  ! hlssink2 target-duration=4 playlist-length=5 max-files=5 location=/var/www/html/segment4_%05d.ts playlist-location=/var/www/html/xil_xcode_stream_scale_360p30.m3u8 \
sc_00.src_3 ! queue ! video/x-raw, width=288, height=160, format=NV12 \
  ! videorate ! video/x-raw, framerate=30/1 \
  ! vvas_xvcuenc name=enc_160p30_dev0_0 dev-idx=0 target-bitrate=625 \
  ! h264parse ! video/x-h264 \
  ! hlssink2 target-duration=4 playlist-length=5 max-files=5 location=/var/www/html/segment5_%05d.ts playlist-location=/var/www/html/xil_xcode_stream_scale_160p30.m3u8 -v
</pre></div>
</div>
<p>Explanation of the pipeline elements and their properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hlssink2</span></code></p>
<ul>
<li><p>HTTP Live Streaming sink/server. Unlike the old hlssink which took a muxed MPEG-TS stream as input, this element takes elementary audio and video streams as input and handles the muxing internally. This element only writes fragments and a playlist file into a specified directory, it does not contain an actual HTTP server to serve these files. Just point an external webserver to the directory with the playlist and fragment files.</p></li>
</ul>
</li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../ffmpeg/quality_analysis.html" class="btn btn-neutral float-left" title="Video Quality Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="filters.html" class="btn btn-neutral float-right" title="GStreamer Examples using Software Filters" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2023, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on May 05, 2023.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>